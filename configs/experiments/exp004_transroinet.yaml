name: "exp004_transroinet"
description: "TransRoiNet: RoiNet with Transformer-enhanced bottleneck"
tags: ["transroinet", "transformer", "residual", "hybrid"]

dataset: "configs/datasets/fives_512.yaml"

data:
  batch_size: 1 # Smaller batch due to transformer + residual blocks memory requirements
  num_workers: 1
  pin_memory: true
  
  augmentation:
    enabled: false
  
  preprocessing:
    normalize: true
    pad_to_multiple: 32

model:
  type: "TransRoiNet"
  in_channels: 3
  out_channels: 1
  depths: [32, 64, 128, 128, 64, 32]  # RoiNet channel progression
  kernel_size: 9                       # Large kernel for residual blocks
  
  # Transformer configuration (lighter than UTrans for bottleneck)
  transformer_depth: 2                 # Number of transformer blocks (lighter than UTrans)
  transformer_heads: 8                 # Number of attention heads
  transformer_mlp_ratio: 4.0           # FFN hidden dim = 4 * embed_dim
  transformer_dropout: 0.1             # Dropout probability
  
  final_activation: "sigmoid"

training:
  epochs: 20
  
  optimizer:
    type: "adam"
    learning_rate: 0.0001              # Same as other models
    weight_decay: 0.0001
  
  scheduler:
    type: "cosine"
    min_lr: 0.000001
  
  loss:
    type: "dice"
    smooth: 0.000001
  
  metrics:
    - "dice"
    - "iou"
  
  mixed_precision: false
  gradient_clip: 1.0
  
  validation:
    frequency: 1
  
  early_stopping:
    enabled: true
    patience: 5
    monitor: "val_dice"
    mode: "max"
  
  checkpoint:
    save_best: true
    save_last: true
    monitor: "val_dice"
    mode: "max"

logging:
  tensorboard: true
  log_images: false

output:
  dir: "outputs/experiments/exp004_transroinet"
  save_predictions: true

seed: 42
device: "cuda"

